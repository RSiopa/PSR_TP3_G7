I need to put a camera in the back of the robot (priority for now)
Things to change in the code:
The robot will not follow a PoseStamped created by me
create the centroid of the object that he needs to catch (as well as the others)
we need to use the formulas given by the vision classes to change that point to a x,y location 
https://pyimagesearch.com/2015/01/19/find-distance-camera-objectmarker-using-python-opencv/ can help
https://www.fdxlabs.com/calculate-x-y-z-real-world-coordinates-from-a-single-camera-using-opencv/
with that the robot can follow the goal
create arguments to choose manual mode and auto mode
create a mask also for the obstacles (or maybe I only need the Laser scanner for that? Will see)


1ยบ method, discover using only the camera
need:
intrisics from the camera : https://answers.ros.org/question/377196/find-intrisic-camera-matrix-from-gazebo-model/
extrinsics from the camera : get him from xacro or tf
problem: can have lots of errors since the camera is not that precise


2ยบ method, discover using camera and laser scanner
need: 
values from the image of the camera
laser scanner values
put the laser values in the image
fusion of sensor data
method used by the professor in this video https://www.youtube.com/watch?v=fhX8FUi68So time 1:20:00 maybe


3ยบ method, discover using camera depth and vetor of 
need: 
https://answers.ros.org/question/367829/converting-image-pixel-coordinates-2dx-y-to-3d-world-coordinatequaternion/
https://github.com/IntelRealSense/realsense-ros/issues/714
values from the depth of the camera
object centroid from object image

problems: easy, fast (idk about precise) OR CAMERA IS NOT DEPTH, DOESN'T WORK



https://answers.ros.org/question/28957/calibrate-gazebo-camera/ extrinsics are not needed in gazebo, we already know the pose of the camera

fuse the Lidar data with the camera, how?
transform the lidar points to pixels
use the camera centroid and see the closest Lidar point
change that point back to the world coordinates

% other method:
change the camera centroid to world point and detect closest lidar point
the advantage its that we don't need to transform the points 2 times.
disadvantage is not having image proof of the values, if something is wrong is hard do decipher

that points are going to send a marker array to rviz !




